{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles-training.xml\narticles-training-text.xml\nThe predictions have been written to the output folder.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %load ./src/semeval-pan-2019-random-baseline.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"Random baseline for the PAN19 hyperpartisan news detection task\"\"\"\n",
    "# Version: 2018-09-24\n",
    "\n",
    "# Parameters:\n",
    "# --inputDataset=<directory>\n",
    "#   Directory that contains the articles XML file with the articles for which a prediction should be made.\n",
    "# --outputDir=<directory>\n",
    "#   Directory to which the predictions will be written. Will be created if it does not exist.\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import gc\n",
    "import getopt\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import xml.sax\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from article import Article\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(42)\n",
    "runOutputFileName = \"prediction.txt\"\n",
    "articles = {}\n",
    "\n",
    "########## SAX ##########\n",
    "\n",
    "class HyperpartisanNewsRandomPredictor(xml.sax.ContentHandler):\n",
    "    def __init__(self, outFile):\n",
    "        xml.sax.ContentHandler.__init__(self)\n",
    "        self.outFile = outFile\n",
    "        self.previousId = \"null\"\n",
    "\n",
    "    def startElement(self, name, attrs):\n",
    "        if name == \"article\":\n",
    "            articleId = attrs.getValue(\"id\") # id of the article for which hyperpartisanship should be predicted\n",
    "            self.previousId = articleId\n",
    "            if articleId not in articles.keys():\n",
    "                articles[articleId] = Article(articleId)\n",
    "            if \"hyperpartisan\" in attrs.keys():\n",
    "                articles[articleId].hyperpartisan = attrs.getValue(\"hyperpartisan\")\n",
    "            if \"bias\" in attrs.keys():\n",
    "                articles[articleId].bias = attrs.getValue(\"bias\")\n",
    "            if \"title\" in attrs.keys():\n",
    "                articles[articleId].title = attrs.getValue(\"title\")\n",
    "\n",
    "            if \"labeled-by\" in attrs.keys():\n",
    "                articles[articleId].labeled = attrs.getValue(\"labeled-by\")\n",
    "            if \"published-at\" in attrs.keys():\n",
    "                articles[articleId].published_at = attrs.getValue(\"published-at\")\n",
    "            prediction = random.choice([\"true\", \"false\"]) # random prediction\n",
    "            confidence = random.random() # random confidence value for prediction\n",
    "            # output format per line: \"<article id> <prediction>[ <confidence>]\"\n",
    "            #   - prediction is either \"true\" (hyperpartisan) or \"false\" (not hyperpartisan)\n",
    "            #   - confidence is an optional value to describe the confidence of the predictor in the prediction---the higher, the more confident\n",
    "            self.outFile.write(articleId + \" \" + prediction + \" \" + str(confidence) + \"\\n\")\n",
    "        if name == \"p\":\n",
    "            articles[self.previousId].count_paragraphs += 1\n",
    "        if name == \"q\":\n",
    "            articles[self.previousId].count_quotes += 1\n",
    "        if name == \"a\":\n",
    "            articles[self.previousId].count_urls += 1\n",
    "\n",
    "    def characters(self, content):\n",
    "        try:\n",
    "            if self.previousId != \"null\":\n",
    "                articles[self.previousId].text.append(content)\n",
    "        except AttributeError:\n",
    "            print(self.previousId)\n",
    "\n",
    "\n",
    "########## MAIN ##########\n",
    "\n",
    "def extract_features(filename):\n",
    "    file = open(filename, encoding=\"ISO-8859-1\").readlines()\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(file)\n",
    "    return vectorizer\n",
    "\n",
    "\n",
    "def main(inputDataset, outputDir):\n",
    "    \"\"\"Main method of this module.\"\"\"\n",
    "\n",
    "    with open(outputDir + \"/\" + runOutputFileName, 'w') as outFile:\n",
    "        for file in os.listdir(inputDataset):\n",
    "            if file.endswith(\".xml\"):\n",
    "                with open(inputDataset + \"/\" + file) as inputRunFile:\n",
    "                    print(file)\n",
    "                    xml.sax.parse(inputRunFile, HyperpartisanNewsRandomPredictor(outFile))\n",
    "\n",
    "    print(\"The predictions have been written to the output folder.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(\"./data/test\", \"./output\")\n",
    "    hedges_vectorizer = extract_features(\"./lists/hedges.txt\")\n",
    "    boosters_vectorizer = extract_features(\"./lists/boosters.txt\")\n",
    "    negatives_vectorizer = extract_features(\"./lists/opinion-lexicon-English/negative-words.txt\")\n",
    "    positives_vectorizer = extract_features(\"./lists/opinion-lexicon-English/positive-words.txt\")\n",
    "    gc.collect()\n",
    "    X = []\n",
    "    y = []\n",
    "    for articleid in articles:\n",
    "        text = articles[articleid].text\n",
    "        articles[articleid].hedges = sum(hedges_vectorizer.transform(text).toarray())\n",
    "        articles[articleid].negatives = sum(negatives_vectorizer.transform(text).toarray())\n",
    "        articles[articleid].positives = sum(positives_vectorizer.transform(text).toarray())\n",
    "        #articles[articleid].boosters = sum(boosters_vectorizer.transform(text).toarray())\n",
    "        features = np.concatenate((articles[articleid].hedges, articles[articleid].negatives,\n",
    "                                   articles[articleid].positives), axis=None)\n",
    "\n",
    "        X.append(features)\n",
    "        if articles[articleid].hyperpartisan == \"true\":\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "        gc.collect()\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def model(x):\n",
    "    return 1 / (1 + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.53      0.64      0.58        64\n           1       0.65      0.54      0.59        79\n\n   micro avg       0.59      0.59      0.59       143\n   macro avg       0.59      0.59      0.59       143\nweighted avg       0.60      0.59      0.59       143\n\n0.5874125874125874\n"
     ]
    }
   ],
   "source": [
    "#all\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "reg = linear_model.LinearRegression().fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "threshold = 0.5\n",
    "print(classification_report(y_test, y_pred > threshold))\n",
    "print(accuracy_score(y_test, y_pred > threshold))\n",
    "# Plot outputs\n",
    "plt.scatter(np.sum(X_test, axis=1), y_test,  color='black')\n",
    "plt.plot(np.sum(X_test, axis=1), y_pred, color='blue', linewidth=1)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title(\"regression on all features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.44      0.55      0.49        64\n           1       0.55      0.44      0.49        79\n\n   micro avg       0.49      0.49      0.49       143\n   macro avg       0.49      0.49      0.49       143\nweighted avg       0.50      0.49      0.49       143\n\n0.48951048951048953\n(431, 120)\n"
     ]
    }
   ],
   "source": [
    "#hedges \n",
    "hedges_index =len(hedges_vectorizer.get_feature_names())\n",
    "x_hedges = X[:, 0:hedges_index]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_hedges, y, test_size=0.33, random_state=42)\n",
    "reg = linear_model.LinearRegression().fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "threshold = 0.5\n",
    "print(classification_report(y_test, y_pred > threshold))\n",
    "print(accuracy_score(y_test, y_pred > threshold))\n",
    "print(x_hedges.shape)\n",
    "\n",
    "plt.scatter(np.sum(X_test, axis=1), y_test,  color='black')\n",
    "plt.plot(np.sum(X_test, axis=1), y_pred, color='blue', linewidth=1)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title(\"hedges regression\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.52      0.75      0.62        64\n           1       0.69      0.44      0.54        79\n\n   micro avg       0.58      0.58      0.58       143\n   macro avg       0.60      0.60      0.58       143\nweighted avg       0.61      0.58      0.57       143\n\n0.5804195804195804\n(431, 4809)\n"
     ]
    }
   ],
   "source": [
    "#negatives\n",
    "negatives_index = (len(negatives_vectorizer.get_feature_names())\n",
    "                   + len(hedges_vectorizer.get_feature_names()))\n",
    "x_negative = X[:, hedges_index: negatives_index]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_negative, y, test_size=0.33, random_state=42)\n",
    "reg = linear_model.LinearRegression().fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "threshold = 0.5\n",
    "print(classification_report(y_test, y_pred > threshold))\n",
    "print(accuracy_score(y_test, y_pred > threshold))\n",
    "print(x_negative.shape)\n",
    "plt.scatter(np.sum(X_test, axis=1), y_test,  color='black')\n",
    "plt.plot(np.sum(X_test, axis=1), y_pred, color='blue', linewidth=1)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title(\"negatives regression\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.53      0.77      0.63        64\n           1       0.71      0.46      0.55        79\n\n   micro avg       0.59      0.59      0.59       143\n   macro avg       0.62      0.61      0.59       143\nweighted avg       0.63      0.59      0.59       143\n\n0.5944055944055944\n(431, 2021)\n"
     ]
    }
   ],
   "source": [
    "#positive\n",
    "positives_index = negatives_index + len(positives_vectorizer.get_feature_names())\n",
    "x_positive = X[:, negatives_index: positives_index]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_positive, y, test_size=0.33, random_state=42)\n",
    "reg = linear_model.LinearRegression().fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "threshold = 0.5\n",
    "print(classification_report(y_test, y_pred > threshold))\n",
    "print(accuracy_score(y_test,y_pred > threshold))\n",
    "print(x_positive.shape)\n",
    "\n",
    "plt.scatter(np.sum(X_test, axis=1), y_test,  color='black')\n",
    "plt.plot(np.sum(X_test, axis=1), y_pred, color='blue', linewidth=1)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title(\"positives regression\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hedges_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positives_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4809"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negatives_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.54      0.69      0.61        64\n           1       0.68      0.53      0.60        79\n\n   micro avg       0.60      0.60      0.60       143\n   macro avg       0.61      0.61      0.60       143\nweighted avg       0.62      0.60      0.60       143\n\n0.6013986013986014\n(431, 6830)\n"
     ]
    }
   ],
   "source": [
    "#combined negatives and positives\n",
    "x_combined = X[:, hedges_index: ]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_combined, y, test_size=0.33, random_state=42)\n",
    "reg = linear_model.LinearRegression().fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "threshold = 0.5\n",
    "print(classification_report(y_test, y_pred > threshold))\n",
    "print(accuracy_score(y_test, y_pred > threshold))\n",
    "print(x_combined.shape)\n",
    "\n",
    "plt.scatter(np.sum(X_test, axis=1), y_test,  color='black')\n",
    "plt.plot(np.sum(X_test, axis=1),  y_pred, color='blue', linewidth=1)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title(\"combined regression\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles) - 230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add unigrams+bigrams + new dictionary lueke + wordnet effect (64+).  save it as sparse matrix and then pickle.  + SVM with linear kernel.\n",
    "#use lueke for sintement analysis. \n",
    "# 1. convert everything to unigrams(tfidf)\n",
    "# 2. for every group of features \"class\" have a model (LR and SVM) \n",
    "# 3. have 1 model that combines all features (LR and SVM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
