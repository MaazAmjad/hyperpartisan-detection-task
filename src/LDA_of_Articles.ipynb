{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tariq/Downloads/code/hyperpartisan-detection-task/src'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -\"- coding: utf-8 -\"-\n",
    "from __future__ import division\n",
    "import re\n",
    "from gensim import corpora, models, similarities\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import operator\n",
    "import nltk\n",
    "import csv\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/tariq/Downloads/datasets/hyperpartisan/\"\n",
    "train_data, label_train = pickle.load(open(path+\"train_v.pkl\", 'rb'))\n",
    "test_data, label_test = pickle.load(open(path+\"test_v.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [[token for token in text if token not in stopwords] for text in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# dictionary = corpora.Dictionary(texts)\n",
    "# print('Done')\n",
    "# corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "# print('Done')\n",
    "lda30 = models.LdaModel(corpus, id2word=dictionary, num_topics=30)\n",
    "# print('Done')\n",
    "corpus_lda = lda[corpus]\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " state year new would percent worker government tax water job people million program health economic\n",
      "\n",
      " said game first year one team time two point new season last like get play\n",
      "\n",
      " said state court law case department new say official federal information county report attorney also\n",
      "\n",
      " de la el en que los del un una por se con para su al\n",
      "\n",
      " war military state government country president israel iraq united attack said force security would russia\n",
      "\n",
      " trump president republican said obama house would campaign election state clinton party democrat vote bill\n",
      "\n",
      " people one like right would know even think way american time dont thing make many\n",
      "\n",
      " said school woman police say student child people family year one city church day home\n",
      "\n",
      " company year stock business million share market sale investor fool one billion revenue also new\n",
      "\n",
      " said percent china reuters market bank year trade price company last billion week new oil\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing the top 15 words in all 10 topics\n",
    "n_words, n_topics = 15, 10\n",
    "for topic in lda.show_topics(n_topics, n_words):\n",
    "    words = \"\"\n",
    "    for i, word in enumerate(topic[1].split('+')):\n",
    "        if i == len(topic[1].split('+')) -1:\n",
    "            words += \" \"+word.split('*')[1][1:-1]\n",
    "        else:\n",
    "            words += \" \"+word.split('*')[1][1:-2]\n",
    "    print(words+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda.save('../model/lda.model')\n",
    "lda =  models.LdaModel.load('../model/lda.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.13011454), (2, 0.038886953), (8, 0.43301708), (9, 0.38928422)]\n",
      "[(0, 0.086071275), (1, 0.11849635), (4, 0.37314054), (5, 0.17873716), (6, 0.24193084)]\n",
      "[(1, 0.5877012), (2, 0.0924903), (6, 0.2964672)]\n",
      "[(2, 0.09024273), (3, 0.0142734805), (5, 0.4748345), (6, 0.022690775), (7, 0.3953401)]\n",
      "[(0, 0.81401384), (1, 0.03584789), (4, 0.08583857), (6, 0.0622012)]\n",
      "[(0, 0.12966111), (4, 0.21084164), (5, 0.04447907), (6, 0.081906565), (9, 0.5299858)]\n",
      "[(2, 0.1651949), (5, 0.30319846), (6, 0.08559188), (7, 0.4400135)]\n",
      "[(1, 0.22099176), (2, 0.23453842), (7, 0.5361849)]\n",
      "[(1, 0.6401535), (2, 0.011698402), (7, 0.3011006), (9, 0.043954)]\n",
      "[(0, 0.119515754), (1, 0.23403215), (2, 0.021193566), (4, 0.07707596), (6, 0.1110752), (7, 0.41095892), (9, 0.016402997)]\n",
      "[(1, 0.10324253), (4, 0.79197776), (5, 0.101874456)]\n",
      "[(0, 0.026244182), (1, 0.08784206), (4, 0.056884337), (5, 0.18468684), (6, 0.4534799), (7, 0.17580177), (8, 0.010569323)]\n",
      "[(1, 0.034060042), (5, 0.90100896), (6, 0.05985754)]\n",
      "[(0, 0.61022395), (1, 0.06158966), (2, 0.045423843), (6, 0.101992264), (7, 0.13487644), (8, 0.044542305)]\n",
      "[(1, 0.14979495), (2, 0.6240599), (5, 0.011887191), (7, 0.21125734)]\n",
      "[(0, 0.17554191), (2, 0.029130865), (5, 0.26831868), (6, 0.36515507), (7, 0.16091172)]\n",
      "[(3, 0.90554565), (9, 0.09150186)]\n",
      "[(0, 0.024429891), (2, 0.06160123), (4, 0.3141093), (6, 0.36286405), (7, 0.22317962)]\n",
      "[(0, 0.054127924), (5, 0.025744798), (6, 0.40681455), (8, 0.5014636)]\n",
      "[(0, 0.051643394), (1, 0.013632538), (2, 0.4782771), (5, 0.08568948), (6, 0.2201295), (7, 0.019319057), (8, 0.11779924)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000,1020):\n",
    "    print(corpus_lda[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = [dictionary.doc2bow(text) for text in test_data]\n",
    "test_lda = lda[test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.092658624), (2, 0.04970208), (6, 0.30957645), (7, 0.3815075), (8, 0.16583888)]\n",
      "[(1, 0.11189037), (5, 0.73696923), (6, 0.14587617)]\n",
      "[(0, 0.21191159), (1, 0.039419394), (2, 0.17823541), (5, 0.021047855), (6, 0.19291544), (7, 0.34206095)]\n",
      "[(0, 0.03869824), (1, 0.036346972), (2, 0.20858952), (5, 0.4685229), (6, 0.06912684), (7, 0.13275798), (8, 0.04505653)]\n",
      "[(0, 0.1668742), (2, 0.33032203), (3, 0.09816907), (4, 0.2403327), (5, 0.15660797)]\n",
      "[(1, 0.34593472), (5, 0.04016196), (6, 0.59798974)]\n",
      "[(0, 0.039931033), (2, 0.14487264), (5, 0.54198956), (6, 0.22201377), (8, 0.048489805)]\n",
      "[(1, 0.06988198), (5, 0.072447516), (6, 0.6489761), (7, 0.19832598)]\n",
      "[(1, 0.03874032), (2, 0.07051369), (4, 0.07116194), (5, 0.06453052), (6, 0.28781584), (7, 0.46114013)]\n",
      "[(0, 0.045261838), (1, 0.08845874), (2, 0.19320361), (5, 0.040055502), (6, 0.33978212), (7, 0.26566914), (8, 0.014931831)]\n",
      "[(0, 0.56611395), (2, 0.06078832), (5, 0.061258074), (7, 0.284979), (8, 0.020972522)]\n",
      "[(0, 0.1946551), (5, 0.54578066), (6, 0.23819132), (9, 0.016154483)]\n",
      "[(1, 0.025841607), (2, 0.20897083), (5, 0.22529292), (6, 0.52876043)]\n",
      "[(0, 0.017676989), (1, 0.04575913), (5, 0.8600437), (6, 0.065867476)]\n",
      "[(2, 0.24798374), (4, 0.012674318), (5, 0.5305599), (6, 0.15671732), (8, 0.049842004)]\n",
      "[(0, 0.09947032), (1, 0.2641883), (3, 0.010568052), (4, 0.15077071), (6, 0.30648854), (8, 0.021979477), (9, 0.14210038)]\n",
      "[(2, 0.6189631), (5, 0.06721888), (6, 0.27351424), (7, 0.03205214)]\n",
      "[(1, 0.16488624), (5, 0.45970517), (6, 0.34019527), (8, 0.031468723)]\n",
      "[(2, 0.51755697), (6, 0.05558849), (8, 0.42071337)]\n",
      "[(0, 0.09586133), (1, 0.03506111), (2, 0.12841798), (5, 0.10375063), (6, 0.6292343)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000,1020):\n",
    "    print(test_lda[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3aee04f45f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../document2topic/training10topics.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_corpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../document2topic/test10topics.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lda =  models.LdaModel.load('../model/lda.model')\n",
    "pickle.dump(corpus,open('../document2topic/training10topics.pkl','wb'))\n",
    "pickle.dump(test_corpus,open('../document2topic/test10topics.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('../document2topic/training10topics.pkl', 'wb') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda30.save('../model/lda30.model')\n",
    "pickle.dump(corpus,open('../document2topic/training30topics.pkl','wb'))\n",
    "pickle.dump(test_corpus,open('../document2topic/test30topics.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # topic distributions per documents with unused topics set to zero\n",
    "# doc_topics = [[]] * len(word_clusters_lda)\n",
    "# j = 0\n",
    "# for doc in word_clusters_lda:\n",
    "#     doc_topics[j] = [0] * lda.num_topics\n",
    "#     i = 0\n",
    "#     while(i<len(doc)):\n",
    "#         temp = doc[i]\n",
    "#         doc_topics[j][temp[0]]=format(temp[1],'.4f')\n",
    "#         i = i + 1\n",
    "#     j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = [ [(0, 0.042757217), (4, 0.66141087), (5, 0.029720547), (6, 0.26050654)],\n",
    "           [(1, 0.98517394)] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = [\"hello\", 'hi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('document2topic/training10topics.csv', 'w',newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        for line in corpus_lda10:\n",
    "            writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
